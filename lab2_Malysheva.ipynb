{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2\n",
    "Выполнила Малышева Екатерина.<br>\n",
    "В качестве данных для обработки используется корпус, составленный в первой лабораторной работе. (Новостной сайт Lenta.ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\katya\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: sklearn in c:\\users\\katya\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\katya\\anaconda3\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: pymorphy2 in c:\\users\\katya\\anaconda3\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: stop_words in c:\\users\\katya\\anaconda3\\lib\\site-packages (2018.7.23)\n",
      "Requirement already satisfied: regex in c:\\users\\katya\\anaconda3\\lib\\site-packages (from nltk) (2020.6.8)\n",
      "Requirement already satisfied: click in c:\\users\\katya\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\katya\\anaconda3\\lib\\site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\katya\\anaconda3\\lib\\site-packages (from nltk) (4.47.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\katya\\anaconda3\\lib\\site-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\katya\\anaconda3\\lib\\site-packages (from wordcloud) (7.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\katya\\anaconda3\\lib\\site-packages (from wordcloud) (3.2.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\katya\\anaconda3\\lib\\site-packages (from wordcloud) (1.18.5)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\katya\\anaconda3\\lib\\site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\katya\\anaconda3\\lib\\site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\katya\\anaconda3\\lib\\site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\katya\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\katya\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\katya\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\katya\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\katya\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\katya\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: six in c:\\users\\katya\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk sklearn wordcloud pymorphy2 stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Katya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Katya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import pymorphy2\n",
    "from scipy.sparse import *\n",
    "import stop_words\n",
    "from nltk.stem.snowball import RussianStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import json \n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://lenta.ru/news/2022/01/19/sosad/</td>\n",
       "      <td>Россиянка назвала главные ошибки при покупке э...</td>\n",
       "      <td>travel/world</td>\n",
       "      <td>Путешествия</td>\n",
       "      <td>Россиянка отдохнула в Египте и назвала худшие ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://lenta.ru/news/2022/01/18/opyatetivyshki/</td>\n",
       "      <td>Раскрыто опасное влияние вышек 5G на полеты</td>\n",
       "      <td>travel/world</td>\n",
       "      <td>Путешествия</td>\n",
       "      <td>Несколько крупнейших американских авиакомпаний...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://lenta.ru/news/2022/01/18/maid/</td>\n",
       "      <td>Названы самые грязные вещи в номерах отелей</td>\n",
       "      <td>travel/world</td>\n",
       "      <td>Путешествия</td>\n",
       "      <td>Горничная Эллиана Мадрид (Elliana Madrid), раб...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://lenta.ru/news/2022/01/18/kakpochemu/</td>\n",
       "      <td>Названа причина экстренной посадки пассажирско...</td>\n",
       "      <td>travel/world</td>\n",
       "      <td>Путешествия</td>\n",
       "      <td>Нарушение системы управления названо предварит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://lenta.ru/news/2022/01/18/podorozhali/</td>\n",
       "      <td>Стало известно о значительном подорожании загр...</td>\n",
       "      <td>travel/world</td>\n",
       "      <td>Путешествия</td>\n",
       "      <td>Исполнительный директор Ассоциации туроператор...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5076</th>\n",
       "      <td>https://lenta.ru/news/2018/08/29/obideli/</td>\n",
       "      <td>Рэпер 50 Cent обиделся на мем и пожелал его ав...</td>\n",
       "      <td>media/memes</td>\n",
       "      <td>Интернет и СМИ</td>\n",
       "      <td>Рэп-исполнитель 50 Cent пожелал смерти авторам...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5077</th>\n",
       "      <td>https://lenta.ru/news/2018/08/25/edro_meme/</td>\n",
       "      <td>В сети призвали вернуть кокаин депутатам</td>\n",
       "      <td>media/memes</td>\n",
       "      <td>Интернет и СМИ</td>\n",
       "      <td>В сети с воодушевлением отреагировали на новос...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5078</th>\n",
       "      <td>https://lenta.ru/news/2018/08/25/joejoe_rip/</td>\n",
       "      <td>Умерла самая известная на планете капибара</td>\n",
       "      <td>media/memes</td>\n",
       "      <td>Интернет и СМИ</td>\n",
       "      <td>Скончался капибара ДжоДжо, который благодаря с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5079</th>\n",
       "      <td>https://lenta.ru/news/2018/08/25/binoculars/</td>\n",
       "      <td>Меркель сочли вуайеристкой</td>\n",
       "      <td>media/memes</td>\n",
       "      <td>Интернет и СМИ</td>\n",
       "      <td>В соцсетях отреагировали на решение канцлера Ф...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5080</th>\n",
       "      <td>https://lenta.ru/news/2018/08/25/otrajenie/</td>\n",
       "      <td>Живущее своей жизнью отражение в зеркале напуг...</td>\n",
       "      <td>media/memes</td>\n",
       "      <td>Интернет и СМИ</td>\n",
       "      <td>Пользователь Twitter под ником jolynn опублико...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5081 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            article_id  \\\n",
       "0              https://lenta.ru/news/2022/01/19/sosad/   \n",
       "1     https://lenta.ru/news/2022/01/18/opyatetivyshki/   \n",
       "2               https://lenta.ru/news/2022/01/18/maid/   \n",
       "3         https://lenta.ru/news/2022/01/18/kakpochemu/   \n",
       "4        https://lenta.ru/news/2022/01/18/podorozhali/   \n",
       "...                                                ...   \n",
       "5076         https://lenta.ru/news/2018/08/29/obideli/   \n",
       "5077       https://lenta.ru/news/2018/08/25/edro_meme/   \n",
       "5078      https://lenta.ru/news/2018/08/25/joejoe_rip/   \n",
       "5079      https://lenta.ru/news/2018/08/25/binoculars/   \n",
       "5080       https://lenta.ru/news/2018/08/25/otrajenie/   \n",
       "\n",
       "                                                  title      category  \\\n",
       "0     Россиянка назвала главные ошибки при покупке э...  travel/world   \n",
       "1         Раскрыто опасное влияние вышек 5G на полеты    travel/world   \n",
       "2         Названы самые грязные вещи в номерах отелей    travel/world   \n",
       "3     Названа причина экстренной посадки пассажирско...  travel/world   \n",
       "4     Стало известно о значительном подорожании загр...  travel/world   \n",
       "...                                                 ...           ...   \n",
       "5076  Рэпер 50 Cent обиделся на мем и пожелал его ав...   media/memes   \n",
       "5077         В сети призвали вернуть кокаин депутатам     media/memes   \n",
       "5078       Умерла самая известная на планете капибара     media/memes   \n",
       "5079                       Меркель сочли вуайеристкой     media/memes   \n",
       "5080  Живущее своей жизнью отражение в зеркале напуг...   media/memes   \n",
       "\n",
       "                   tags                                               text  \n",
       "0        Путешествия     Россиянка отдохнула в Египте и назвала худшие ...  \n",
       "1        Путешествия     Несколько крупнейших американских авиакомпаний...  \n",
       "2        Путешествия     Горничная Эллиана Мадрид (Elliana Madrid), раб...  \n",
       "3        Путешествия     Нарушение системы управления названо предварит...  \n",
       "4        Путешествия     Исполнительный директор Ассоциации туроператор...  \n",
       "...                 ...                                                ...  \n",
       "5076  Интернет и СМИ     Рэп-исполнитель 50 Cent пожелал смерти авторам...  \n",
       "5077  Интернет и СМИ     В сети с воодушевлением отреагировали на новос...  \n",
       "5078  Интернет и СМИ     Скончался капибара ДжоДжо, который благодаря с...  \n",
       "5079  Интернет и СМИ     В соцсетях отреагировали на решение канцлера Ф...  \n",
       "5080  Интернет и СМИ     Пользователь Twitter под ником jolynn опублико...  \n",
       "\n",
       "[5081 rows x 5 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data = pd.read_json(\"catalog.json\", lines=True)\n",
    "text_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Text preprocessing \n",
    "\n",
    "В данной части входные данные будут предобработаны, в частности будут удалены знаки препинания, ненужные символы и стоп-слова, а так же корпус будет токенезирван по предложениям и словам. Слова будут приведены в нормальную форму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess(text_input):\n",
    "    \n",
    "    # копируем текст:\n",
    "    text_processed = text_input[:]\n",
    "    \n",
    "    # переводем текст в lowercase:\n",
    "    text_processed = text_processed.lower()\n",
    "    \n",
    "    # удаляем лишние пробелы:\n",
    "    text_processed = re.sub(r'\\s+', ' ', text_processed)\n",
    "    \n",
    "    \n",
    "    # удалим html теги из текста (если такие есть):\n",
    "    text_processed =  re.sub(r'\\<[^>]*\\>', '',  text_processed)\n",
    "    \n",
    "    # удалим ссылки:\n",
    "    text_processed = re.sub(r\"https?://[^,\\s]+,?\", \"\", text_processed)\n",
    "    \n",
    "    # токенизирем по предложению\n",
    "    text_sent_tokenized = sent_tokenize(text_processed)\n",
    "    \n",
    "    # удалим специальны символы цифры и пунктуацию\n",
    "    symbol_to_exclude = u''.join(['№', '«', 'ђ', '°', '±', '‚', 'ћ', '‰', '…', '»', 'ѓ', 'µ', '·', 'ґ', 'њ', 'ї', 'џ', 'є', '‹',\n",
    "                                '‡', '†', '¶', 'ќ', '€', '“', 'ў', '§', '„', '”', '\\ufeff', '’', 'љ', '›', '•', '—', '‘', \n",
    "                                '\\x7f', '\\xad', '¤', '\\xa0'])\n",
    "    \n",
    "    regex_punct = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    regex_dig = re.compile('[%s]' % re.escape(string.digits))\n",
    "    regex_symb = re.compile('[%s]' % re.escape(symbol_to_exclude))\n",
    "    \n",
    "    text_sent_tokenized  = [regex_symb.sub(' ', sent) for sent in text_sent_tokenized]\n",
    "    text_sent_tokenized  = [regex_dig.sub(' ', sent) for sent in text_sent_tokenized]\n",
    "    text_sent_tokenized  = [regex_punct.sub(' ', sent) for sent in text_sent_tokenized]\n",
    "    \n",
    "    text_sent_tokenized = [re.sub(r'\\s+', ' ', sent) for sent in text_sent_tokenized]\n",
    "    \n",
    "    # токенизируем по словам\n",
    "    text_word_tokenized = [word_tokenize(sent) for sent in text_sent_tokenized]\n",
    "    \n",
    "    # приведем слова к нормальной форме \n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    \n",
    "    text_normalized = []\n",
    "    for sent in text_word_tokenized:\n",
    "        text_normalized.append([morph.parse(word)[0].normal_form for word in sent])\n",
    "        \n",
    "    # удалим стоп-слова \n",
    "    for sent in text_normalized:\n",
    "        for word in sent:\n",
    "            if word in stop_words.get_stop_words('ru'):\n",
    "                sent.remove(word)\n",
    "                #print(word)\n",
    "    \n",
    "    \n",
    "    text_final =' '.join([' '.join(sent) for sent in text_normalized])\n",
    "    return  text_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Article preprocessing progress: 100%|██████████████████████████████████████████████| 5081/5081 [50:38<00:00,  1.67it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_data = text_data.copy()\n",
    "for i in  tqdm(range(text_data.shape[0]), desc = 'Article preprocessing progress'):\n",
    "    preprocessed_data['text'][i]= text_preprocess(text_data['text'][i])\n",
    "    preprocessed_data['tags'][i] = text_preprocess(text_data['tags'][i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://lenta.ru/news/2022/01/19/sosad/</td>\n",
       "      <td>Россиянка назвала главные ошибки при покупке э...</td>\n",
       "      <td>travel/world</td>\n",
       "      <td>путешествие</td>\n",
       "      <td>россиянка отдохнуть египет назвать плохой экск...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://lenta.ru/news/2022/01/18/opyatetivyshki/</td>\n",
       "      <td>Раскрыто опасное влияние вышек 5G на полеты</td>\n",
       "      <td>travel/world</td>\n",
       "      <td>путешествие</td>\n",
       "      <td>крупный американский авиакомпания раскрыть опа...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://lenta.ru/news/2022/01/18/maid/</td>\n",
       "      <td>Названы самые грязные вещи в номерах отелей</td>\n",
       "      <td>travel/world</td>\n",
       "      <td>путешествие</td>\n",
       "      <td>горничная эллиана мадрид elliana madrid работа...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://lenta.ru/news/2022/01/18/kakpochemu/</td>\n",
       "      <td>Названа причина экстренной посадки пассажирско...</td>\n",
       "      <td>travel/world</td>\n",
       "      <td>путешествие</td>\n",
       "      <td>нарушение система управление назвать предварит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://lenta.ru/news/2022/01/18/podorozhali/</td>\n",
       "      <td>Стало известно о значительном подорожании загр...</td>\n",
       "      <td>travel/world</td>\n",
       "      <td>путешествие</td>\n",
       "      <td>исполнительный директор ассоциация туроператор...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5076</th>\n",
       "      <td>https://lenta.ru/news/2018/08/29/obideli/</td>\n",
       "      <td>Рэпер 50 Cent обиделся на мем и пожелал его ав...</td>\n",
       "      <td>media/memes</td>\n",
       "      <td>интернет сми</td>\n",
       "      <td>рэп исполнитель cent пожелать смерть автор мем...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5077</th>\n",
       "      <td>https://lenta.ru/news/2018/08/25/edro_meme/</td>\n",
       "      <td>В сети призвали вернуть кокаин депутатам</td>\n",
       "      <td>media/memes</td>\n",
       "      <td>интернет сми</td>\n",
       "      <td>сеть воодушевление отреагировать новость обнар...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5078</th>\n",
       "      <td>https://lenta.ru/news/2018/08/25/joejoe_rip/</td>\n",
       "      <td>Умерла самая известная на планете капибара</td>\n",
       "      <td>media/memes</td>\n",
       "      <td>интернет сми</td>\n",
       "      <td>скончаться капибара джоджо благодаря свой друж...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5079</th>\n",
       "      <td>https://lenta.ru/news/2018/08/25/binoculars/</td>\n",
       "      <td>Меркель сочли вуайеристкой</td>\n",
       "      <td>media/memes</td>\n",
       "      <td>интернет сми</td>\n",
       "      <td>соцсеть отреагировать решение канцлер фрг анге...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5080</th>\n",
       "      <td>https://lenta.ru/news/2018/08/25/otrajenie/</td>\n",
       "      <td>Живущее своей жизнью отражение в зеркале напуг...</td>\n",
       "      <td>media/memes</td>\n",
       "      <td>интернет сми</td>\n",
       "      <td>пользователь twitter ник jolynn опубликовать с...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5081 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            article_id  \\\n",
       "0              https://lenta.ru/news/2022/01/19/sosad/   \n",
       "1     https://lenta.ru/news/2022/01/18/opyatetivyshki/   \n",
       "2               https://lenta.ru/news/2022/01/18/maid/   \n",
       "3         https://lenta.ru/news/2022/01/18/kakpochemu/   \n",
       "4        https://lenta.ru/news/2022/01/18/podorozhali/   \n",
       "...                                                ...   \n",
       "5076         https://lenta.ru/news/2018/08/29/obideli/   \n",
       "5077       https://lenta.ru/news/2018/08/25/edro_meme/   \n",
       "5078      https://lenta.ru/news/2018/08/25/joejoe_rip/   \n",
       "5079      https://lenta.ru/news/2018/08/25/binoculars/   \n",
       "5080       https://lenta.ru/news/2018/08/25/otrajenie/   \n",
       "\n",
       "                                                  title      category  \\\n",
       "0     Россиянка назвала главные ошибки при покупке э...  travel/world   \n",
       "1         Раскрыто опасное влияние вышек 5G на полеты    travel/world   \n",
       "2         Названы самые грязные вещи в номерах отелей    travel/world   \n",
       "3     Названа причина экстренной посадки пассажирско...  travel/world   \n",
       "4     Стало известно о значительном подорожании загр...  travel/world   \n",
       "...                                                 ...           ...   \n",
       "5076  Рэпер 50 Cent обиделся на мем и пожелал его ав...   media/memes   \n",
       "5077         В сети призвали вернуть кокаин депутатам     media/memes   \n",
       "5078       Умерла самая известная на планете капибара     media/memes   \n",
       "5079                       Меркель сочли вуайеристкой     media/memes   \n",
       "5080  Живущее своей жизнью отражение в зеркале напуг...   media/memes   \n",
       "\n",
       "              tags                                               text  \n",
       "0      путешествие  россиянка отдохнуть египет назвать плохой экск...  \n",
       "1      путешествие  крупный американский авиакомпания раскрыть опа...  \n",
       "2      путешествие  горничная эллиана мадрид elliana madrid работа...  \n",
       "3      путешествие  нарушение система управление назвать предварит...  \n",
       "4      путешествие  исполнительный директор ассоциация туроператор...  \n",
       "...            ...                                                ...  \n",
       "5076  интернет сми  рэп исполнитель cent пожелать смерть автор мем...  \n",
       "5077  интернет сми  сеть воодушевление отреагировать новость обнар...  \n",
       "5078  интернет сми  скончаться капибара джоджо благодаря свой друж...  \n",
       "5079  интернет сми  соцсеть отреагировать решение канцлер фрг анге...  \n",
       "5080  интернет сми  пользователь twitter ник jolynn опубликовать с...  \n",
       "\n",
       "[5081 rows x 5 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data.to_excel('preprocessed_corpus.xlsx')# сохраняем обработанные тексты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Разделение на test/train и векторизация\n",
    "Для векторизации используем CountVectorizer - Методика \"Мешок Слов\". Но до этого разделим корпус на обучающую и тестовую  выборки с пропорцией 70/30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocessed_data['text']\n",
    "y = preprocessed_data['tags']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.3, random_state=42, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df=10)\n",
    "\n",
    "X_train_bow = vect.fit_transform(X_train)\n",
    "X_test_bow = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. ML классификаторы\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим наиболее популярные классификаторы (https://tproger.ru/translations/scikit-learn-in-python/). Для улучшения метрик параметры будут подбираться с помощью GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Наивный Байесовский классификатор \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      " интернет сми       0.93      0.79      0.85        99\n",
      "          мир       0.92      0.94      0.93       266\n",
      "наука техника       0.90      0.95      0.93       351\n",
      "  путешествие       0.97      0.95      0.96       268\n",
      "        спорт       0.98      0.98      0.98       282\n",
      "     ценность       0.97      0.95      0.96       259\n",
      "\n",
      "     accuracy                           0.94      1525\n",
      "    macro avg       0.95      0.93      0.94      1525\n",
      " weighted avg       0.95      0.94      0.94      1525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf_NB = MultinomialNB()\n",
    "clf_NB.fit(X_train_bow, y_train)\n",
    "\n",
    "y_pred_NB = clf.predict(X_test_bow)\n",
    "print(classification_report(y_test, y_pred_NB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Логистическая регрессия "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 80 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed:   46.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 7.1, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "\n",
    "params = {\n",
    "    'C': np.arange(0.1, 20, 1), # регуляризация\n",
    "    'penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
    "}\n",
    "\n",
    "clf_LR = LogisticRegression(penalty = 'l2')\n",
    "grid_LR = GridSearchCV(clf_LR , params, cv=2, verbose = 1)\n",
    "\n",
    "grid_LR.fit(X_train_bow, y_train)\n",
    "grid_LR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      " интернет сми       0.91      0.93      0.92        97\n",
      "          мир       0.96      0.92      0.94       277\n",
      "наука техника       0.96      0.97      0.96       346\n",
      "  путешествие       0.96      0.98      0.97       264\n",
      "        спорт       1.00      0.98      0.99       286\n",
      "     ценность       0.97      0.98      0.97       255\n",
      "\n",
      "     accuracy                           0.96      1525\n",
      "    macro avg       0.96      0.96      0.96      1525\n",
      " weighted avg       0.96      0.96      0.96      1525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_LR= grid_LR.predict(X_test_bow)\n",
    "print(classification_report(y_pred_LR, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия справилась с классификацией текстов лучше, чем Наивный Байессовский алгоритм,заметны улучшения по всем метрикам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      " интернет сми       0.74      0.65      0.69        99\n",
      "          мир       0.79      0.80      0.80       266\n",
      "наука техника       0.82      0.84      0.83       351\n",
      "  путешествие       0.91      0.90      0.90       268\n",
      "        спорт       0.92      0.94      0.93       282\n",
      "     ценность       0.87      0.87      0.87       259\n",
      "\n",
      "     accuracy                           0.85      1525\n",
      "    macro avg       0.84      0.83      0.84      1525\n",
      " weighted avg       0.85      0.85      0.85      1525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train_bow, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_bow)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При дефолтных параметрах результат работы DecisionTree классификатора на порядок ниже, чем у предыдущих алгоритмов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### k - ближащих соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:    6.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metric': 'minkowski', 'n_neighbors': 2, 'weights': 'distance'}"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "params = {\n",
    "    'n_neighbors': [2, 4, 8, 16],\n",
    "    'weights': ['distance', 'uniform'],\n",
    "    'metric': ['minkowski', 'euclidean']\n",
    "}\n",
    "\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "\n",
    "grid_KNN = GridSearchCV(clf_KNN , params, cv=2, verbose = 1)\n",
    "\n",
    "grid_KNN.fit(X_train_bow, y_train)\n",
    "grid_KNN.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      " интернет сми       0.45      0.87      0.60        52\n",
      "          мир       0.71      0.85      0.77       222\n",
      "наука техника       0.61      0.97      0.75       220\n",
      "  путешествие       0.78      0.93      0.85       224\n",
      "        спорт       1.00      0.45      0.62       623\n",
      "     ценность       0.71      0.99      0.83       184\n",
      "\n",
      "     accuracy                           0.73      1525\n",
      "    macro avg       0.71      0.84      0.73      1525\n",
      " weighted avg       0.81      0.73      0.72      1525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_KNN= grid_KNN.predict(X_test_bow)\n",
    "print(classification_report(y_pred_KNN, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При подборе гиперпараметров удалось улучшить accuracy до 0.73, что сильно уступает рассмотренным ранее алгоритмам. Судя по графе support, алгоритм склонен сильно переопределять категорию \"спорт\" и недооценивать \"интернет и сми\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      " интернет сми       0.97      0.72      0.83        99\n",
      "          мир       0.89      0.94      0.92       266\n",
      "наука техника       0.92      0.94      0.93       351\n",
      "  путешествие       0.96      0.95      0.95       268\n",
      "        спорт       0.98      0.99      0.98       282\n",
      "     ценность       0.93      0.94      0.94       259\n",
      "\n",
      "     accuracy                           0.94      1525\n",
      "    macro avg       0.94      0.91      0.92      1525\n",
      " weighted avg       0.94      0.94      0.94      1525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_RFC = RandomForestClassifier()\n",
    "clf_RFC.fit(X_train_bow, y_train)\n",
    "#print(clf.get_params())\n",
    "y_pred_RFC = clf_RFC.predict(X_test_bow)\n",
    "print(classification_report(y_test, y_pred_RFC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При стандартных параметрах у Random Forest и Наивного Байесовского алгоритма метрики имеют приближенные значения и accuracy достигает достаточно высоких значений - 0.94."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Метод опорных векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      " интернет сми       0.93      0.79      0.85        99\n",
      "          мир       0.92      0.94      0.93       266\n",
      "наука техника       0.90      0.95      0.93       351\n",
      "  путешествие       0.97      0.95      0.96       268\n",
      "        спорт       0.98      0.98      0.98       282\n",
      "     ценность       0.97      0.95      0.96       259\n",
      "\n",
      "     accuracy                           0.94      1525\n",
      "    macro avg       0.95      0.93      0.94      1525\n",
      " weighted avg       0.95      0.94      0.94      1525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train_bow, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_bow)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 27 candidates, totalling 54 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.231, total=  10.6s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.231, total=   7.6s\n",
      "[CV] C=0.1, gamma=1, kernel=poly .....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   18.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=0.1, gamma=1, kernel=poly, score=0.624, total=   6.7s\n",
      "[CV] C=0.1, gamma=1, kernel=poly .....................................\n",
      "[CV] ......... C=0.1, gamma=1, kernel=poly, score=0.667, total=   6.7s\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=0.1, gamma=1, kernel=sigmoid, score=0.380, total=   6.9s\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=0.1, gamma=1, kernel=sigmoid, score=0.376, total=   7.3s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.231, total=   7.2s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.231, total=  14.1s\n",
      "[CV] C=0.1, gamma=0.1, kernel=poly ...................................\n",
      "[CV] ....... C=0.1, gamma=0.1, kernel=poly, score=0.624, total=  12.2s\n",
      "[CV] C=0.1, gamma=0.1, kernel=poly ...................................\n",
      "[CV] ....... C=0.1, gamma=0.1, kernel=poly, score=0.667, total=   7.2s\n",
      "[CV] C=0.1, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] .... C=0.1, gamma=0.1, kernel=sigmoid, score=0.811, total=   4.7s\n",
      "[CV] C=0.1, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] .... C=0.1, gamma=0.1, kernel=sigmoid, score=0.804, total=   4.6s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.394, total=   7.5s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.399, total=   7.4s\n",
      "[CV] C=0.1, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ...... C=0.1, gamma=0.01, kernel=poly, score=0.557, total=  10.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ...... C=0.1, gamma=0.01, kernel=poly, score=0.507, total=  14.5s\n",
      "[CV] C=0.1, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ... C=0.1, gamma=0.01, kernel=sigmoid, score=0.906, total=   6.2s\n",
      "[CV] C=0.1, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ... C=0.1, gamma=0.01, kernel=sigmoid, score=0.898, total=   7.1s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.272, total=  10.1s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.273, total=   8.4s\n",
      "[CV] C=1, gamma=1, kernel=poly .......................................\n",
      "[CV] ........... C=1, gamma=1, kernel=poly, score=0.624, total=   7.2s\n",
      "[CV] C=1, gamma=1, kernel=poly .......................................\n",
      "[CV] ........... C=1, gamma=1, kernel=poly, score=0.667, total=  14.6s\n",
      "[CV] C=1, gamma=1, kernel=sigmoid ....................................\n",
      "[CV] ........ C=1, gamma=1, kernel=sigmoid, score=0.393, total=   6.9s\n",
      "[CV] C=1, gamma=1, kernel=sigmoid ....................................\n",
      "[CV] ........ C=1, gamma=1, kernel=sigmoid, score=0.372, total=   5.8s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.273, total=   7.4s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.274, total=   7.5s\n",
      "[CV] C=1, gamma=0.1, kernel=poly .....................................\n",
      "[CV] ......... C=1, gamma=0.1, kernel=poly, score=0.624, total=   8.1s\n",
      "[CV] C=1, gamma=0.1, kernel=poly .....................................\n",
      "[CV] ......... C=1, gamma=0.1, kernel=poly, score=0.667, total=   7.1s\n",
      "[CV] C=1, gamma=0.1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=1, gamma=0.1, kernel=sigmoid, score=0.696, total=   3.1s\n",
      "[CV] C=1, gamma=0.1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=1, gamma=0.1, kernel=sigmoid, score=0.684, total=   5.3s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.875, total=  16.5s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.867, total=  13.9s\n",
      "[CV] C=1, gamma=0.01, kernel=poly ....................................\n",
      "[CV] ........ C=1, gamma=0.01, kernel=poly, score=0.664, total=   7.5s\n",
      "[CV] C=1, gamma=0.01, kernel=poly ....................................\n",
      "[CV] ........ C=1, gamma=0.01, kernel=poly, score=0.642, total=   7.5s\n",
      "[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n",
      "[CV] ..... C=1, gamma=0.01, kernel=sigmoid, score=0.938, total=   2.6s\n",
      "[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n",
      "[CV] ..... C=1, gamma=0.01, kernel=sigmoid, score=0.940, total=   2.7s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.272, total=  10.9s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.273, total=  10.4s\n",
      "[CV] C=10, gamma=1, kernel=poly ......................................\n",
      "[CV] .......... C=10, gamma=1, kernel=poly, score=0.624, total=   7.3s\n",
      "[CV] C=10, gamma=1, kernel=poly ......................................\n",
      "[CV] .......... C=10, gamma=1, kernel=poly, score=0.667, total=   6.9s\n",
      "[CV] C=10, gamma=1, kernel=sigmoid ...................................\n",
      "[CV] ....... C=10, gamma=1, kernel=sigmoid, score=0.379, total=   4.0s\n",
      "[CV] C=10, gamma=1, kernel=sigmoid ...................................\n",
      "[CV] ....... C=10, gamma=1, kernel=sigmoid, score=0.377, total=   4.3s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.273, total=   7.7s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.276, total=   7.4s\n",
      "[CV] C=10, gamma=0.1, kernel=poly ....................................\n",
      "[CV] ........ C=10, gamma=0.1, kernel=poly, score=0.624, total=   9.0s\n",
      "[CV] C=10, gamma=0.1, kernel=poly ....................................\n",
      "[CV] ........ C=10, gamma=0.1, kernel=poly, score=0.667, total=  13.5s\n",
      "[CV] C=10, gamma=0.1, kernel=sigmoid .................................\n",
      "[CV] ..... C=10, gamma=0.1, kernel=sigmoid, score=0.659, total=   4.6s\n",
      "[CV] C=10, gamma=0.1, kernel=sigmoid .................................\n",
      "[CV] ..... C=10, gamma=0.1, kernel=sigmoid, score=0.686, total=   3.9s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.886, total=   7.7s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.879, total=   7.0s\n",
      "[CV] C=10, gamma=0.01, kernel=poly ...................................\n",
      "[CV] ....... C=10, gamma=0.01, kernel=poly, score=0.624, total=   7.9s\n",
      "[CV] C=10, gamma=0.01, kernel=poly ...................................\n",
      "[CV] ....... C=10, gamma=0.01, kernel=poly, score=0.670, total=   7.3s\n",
      "[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n",
      "[CV] .... C=10, gamma=0.01, kernel=sigmoid, score=0.889, total=   2.0s\n",
      "[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n",
      "[CV] .... C=10, gamma=0.01, kernel=sigmoid, score=0.901, total=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  54 out of  54 | elapsed:  6.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 0.01, 'kernel': 'sigmoid'}"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'C': [0.1, 1, 10], \n",
    "    'gamma': [1, 0.1, 0.01], \n",
    "    'kernel': ['rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "gs_svm = GridSearchCV(\n",
    "    SVC(random_state=42),\n",
    "    params,\n",
    "    verbose=3,\n",
    "    cv=2,\n",
    ")\n",
    "\n",
    "\n",
    "gs_svm.fit(X_train_bow, y_train)\n",
    "gs_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      " интернет сми       0.92      0.91      0.91       100\n",
      "          мир       0.92      0.89      0.90       275\n",
      "наука техника       0.94      0.95      0.94       347\n",
      "  путешествие       0.94      0.96      0.95       262\n",
      "        спорт       1.00      0.98      0.99       287\n",
      "     ценность       0.95      0.97      0.96       254\n",
      "\n",
      "     accuracy                           0.95      1525\n",
      "    macro avg       0.94      0.94      0.94      1525\n",
      " weighted avg       0.95      0.95      0.95      1525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs_svm.predict(X_test_bow)\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выводы\n",
    "Из рассмотренных алгоритмов классификации наиболее высокие метрики показала Логистическая регрессия - accuracy достигла 96%. Более того, все остальные метрики - precision, f1, recall - оставались выше 90%.\n",
    "Также высокие метрики были у метода опорных векторов (SVC) - accuracy - 95%.\n",
    "Наиболее худшим алгоритмом для даннрой задачи классификации оказался метод k - ближайших соседей, accuracy достигло все лишь 73%. Более того, алгоритм неравномерно определял классы (имел тендентцию переопределять категорию \"спорт\").\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
